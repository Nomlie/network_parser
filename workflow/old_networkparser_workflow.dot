digraph NetworkParser_Flow_Detailed {
  // ─────────────────────────────────────────────────────────────
  // NetworkParser — very detailed, script-faithful pipeline flow
  // Matches the narrative: CLI → DataLoader → pre-tree filtering → tree
  // → post-tree confidence + epistasis → optional validation → final JSON.
  // ─────────────────────────────────────────────────────────────

  rankdir=TB;
  labelloc="t";
  fontsize=20;
  fontname="Helvetica,Arial,sans-serif";
  label="NetworkParser — Detailed Pipeline Flow (script-faithful)\nInput → Matrix construction → Pre-tree statistical filtering → Decision tree → Post-tree confidence + epistasis → Optional validation → Final JSON";

  graph [splines=ortho, nodesep=0.45, ranksep=0.7];
  node  [shape=box, style="rounded,filled", fontname="Helvetica,Arial,sans-serif", fontsize=10, penwidth=1.15, fillcolor="#eef5ff"];
  edge  [fontname="Helvetica,Arial,sans-serif", fontsize=9, penwidth=1.1, arrowsize=0.9, color="#444"];

  // ─────────────────────────────────────────────────────────────
  // STAGE 0 — CLI
  // ─────────────────────────────────────────────────────────────
  subgraph cluster_cli {
    label="Stage 0 — CLI entry (cli.py)";
    labelloc="t";
    fontsize=14;
    style="rounded";
    color="#c9d7f0";

    cli_args [label=<
      <B>Parse CLI args</B><BR ALIGN="LEFT"/>
      • --genomic: file OR directory (VCF/VCF.gz/CSV/TSV)<BR ALIGN="LEFT"/>
      • --meta: optional metadata table (CSV/TSV)<BR ALIGN="LEFT"/>
      • --label: metadata column for phenotype / group<BR ALIGN="LEFT"/>
      • --known_markers: optional marker list<BR ALIGN="LEFT"/>
      • --ref_fasta: optional FASTA for normalization<BR ALIGN="LEFT"/>
      • --config: JSON overrides<BR ALIGN="LEFT"/>
      • --validate_statistics / --validate_interactions flags
    >];

    cli_cfg [label=<
      <B>Load config</B><BR ALIGN="LEFT"/>
      NetworkParserConfig() defaults<BR ALIGN="LEFT"/>
      Apply JSON overrides (shallow field update)
    >];

    cli_call [label=<
      <B>Call pipeline</B><BR ALIGN="LEFT"/>
      run_networkparser_analysis(...) → NetworkParser.run_pipeline(...)
    >];

    cli_args -> cli_cfg -> cli_call;
  }

  // ─────────────────────────────────────────────────────────────
  // ORCHESTRATOR
  // ─────────────────────────────────────────────────────────────
  subgraph cluster_orch {
    label="Orchestrator (network_parser.py)";
    labelloc="t";
    fontsize=14;
    style="rounded";
    color="#c9d7f0";

    np_init [label=<
      <B>Instantiate components</B><BR ALIGN="LEFT"/>
      • DataLoader(config)<BR ALIGN="LEFT"/>
      • EnhancedDecisionTreeBuilder(config)<BR ALIGN="LEFT"/>
      • StatisticalValidator(config)
    >];

    np_run [label=<
      <B>run_pipeline()</B><BR ALIGN="LEFT"/>
      1) Build genomic matrix<BR ALIGN="LEFT"/>
      2) Load metadata + labels<BR ALIGN="LEFT"/>
      3) Discover features + interactions (tree-based)<BR ALIGN="LEFT"/>
      4) Optional validation (if flags)<BR ALIGN="LEFT"/>
      5) Save final JSON report
    >];

    cli_call -> np_init -> np_run;
  }

  // ─────────────────────────────────────────────────────────────
  // STAGE 1 — DATA LOADER
  // ─────────────────────────────────────────────────────────────
  subgraph cluster_loader {
    label="Stage 1 — Matrix construction (data_loader.py)";
    labelloc="t";
    fontsize=14;
    style="rounded";
    color="#d7e3f7";

    dl_route [label=<
      <B>load_genomic_matrix(genomic_path)</B><BR ALIGN="LEFT"/>
      Route by input type:<BR ALIGN="LEFT"/>
      • directory → folder-of-VCFs mode<BR ALIGN="LEFT"/>
      • .vcf / .vcf.gz → single-VCF mode<BR ALIGN="LEFT"/>
      • .csv / .tsv → prebuilt matrix mode<BR ALIGN="LEFT"/>
      • FASTA → not implemented
    >];

    // Directory branch
    dl_dir [label=<
      <B>Directory input</B><BR ALIGN="LEFT"/>
      Collect *.vcf.gz<BR ALIGN="LEFT"/>
      Ensure each has tabix index (*.tbi)<BR ALIGN="LEFT"/>
      Parallel threads: ThreadPoolExecutor
    >];

    dl_choose [label=<
      <B>Choose directory strategy</B><BR ALIGN="LEFT"/>
      • UNION-of-sites mode (large cohorts / ALT-only VCFs)<BR ALIGN="LEFT"/>
      • MERGE-then-PARSE mode (smaller cohorts)
    >];

    // UNION-of-sites details
    union0 [label=<
      <B>UNION mode — PASS 0 (sample IDs)</B><BR ALIGN="LEFT"/>
      bcftools query -l per VCF<BR ALIGN="LEFT"/>
      Build ordered sample list (don’t trust filenames)
    >];

    union1 [label=<
      <B>UNION mode — PASS 1 (global feature universe)</B><BR ALIGN="LEFT"/>
      For each sample VCF, stream variants via bcftools query:<BR ALIGN="LEFT"/>
      • Fields: CHROM, POS, REF, ALT, GT, DP<BR ALIGN="LEFT"/>
      Hard filters while streaming:<BR ALIGN="LEFT"/>
      • Skip missing GT<BR ALIGN="LEFT"/>
      • Skip multiallelic ALT (',' in ALT)<BR ALIGN="LEFT"/>
      • SNP-only: len(REF)==1 &amp; len(ALT)==1<BR ALIGN="LEFT"/>
      • Canonical bases A/C/G/T only<BR ALIGN="LEFT"/>
      • Optional DP gate in union mode (union_dp_min)<BR ALIGN="LEFT"/>
      Output:<BR ALIGN="LEFT"/>
      • variant_string → column_index map<BR ALIGN="LEFT"/>
      • per-sample set of present variant indices
    >];

    union2 [label=<
      <B>UNION mode — PASS 2 (matrix build)</B><BR ALIGN="LEFT"/>
      If scipy.sparse available → build CSR matrix<BR ALIGN="LEFT"/>
      Else → dense fallback (small only)<BR ALIGN="LEFT"/>
      Optional: integer feature IDs + lookup table<BR ALIGN="LEFT"/>
      Save genomic_matrix.csv
    >];

    union_sem [label=<
      <B>UNION mode semantic assumption</B><BR ALIGN="LEFT"/>
      ALT-only single-sample VCF absent record ⇒ encode as reference (0)<BR ALIGN="LEFT"/>
      Not treated as missing
    > fillcolor="#fff2cc"];

    // MERGE-then-PARSE details
    merge0 [label=<
      <B>MERGE-then-PARSE</B><BR ALIGN="LEFT"/>
      bcftools merge -Oz --threads … → merged.vcf.gz<BR ALIGN="LEFT"/>
      tabix -p vcf merged.vcf.gz<BR ALIGN="LEFT"/>
      Then run single-VCF pipeline on merged file
    >];

    // Single VCF bcftools pipeline details
    vcf0 [label=<
      <B>Single VCF mode</B><BR ALIGN="LEFT"/>
      Work in temp directory<BR ALIGN="LEFT"/>
      Use bcftools (+ tabix for bgzip output)
    >];

    vcf1 [label=<
      <B>(Optional) Normalize</B><BR ALIGN="LEFT"/>
      If --ref_fasta provided:<BR ALIGN="LEFT"/>
      bcftools norm -f ref.fa -m- -any<BR ALIGN="LEFT"/>
      (left align + split multiallelic representations)
    >];

    vcf2 [label=<
      <B>Filter biallelic SNPs</B><BR ALIGN="LEFT"/>
      bcftools view -m2 -M2 -v snps
    >];

    vcf3 [label=<
      <B>Variant-level QC</B><BR ALIGN="LEFT"/>
      bcftools filter -e &quot;QUAL&lt;min_qual || INFO/DP&lt;min_dp&quot;<BR ALIGN="LEFT"/>
      (DP clause applied only if INFO/DP exists)
    >];

    vcf4 [label=<
      <B>Genotype-level QC masking</B><BR ALIGN="LEFT"/>
      If FORMAT tags exist (GQ/DP):<BR ALIGN="LEFT"/>
      bcftools filter -S . -e &quot;FMT/GQ&lt;min_gq || FMT/DP&lt;min_fmt_dp&quot;<BR ALIGN="LEFT"/>
      Low-quality genotypes → set to missing (.)
    >];

    vcf5 [label=<
      <B>Remove invariant sites</B><BR ALIGN="LEFT"/>
      bcftools view -i &quot;MAX(AC)&gt;0&quot;
    >];

    vcf6 [label=<
      <B>Remove SNPs near indels/gaps</B><BR ALIGN="LEFT"/>
      bcftools filter --SnpGap min_spacing_bp
    >];

    vcf7 [label=<
      <B>Extract GT → 0/1 matrix</B><BR ALIGN="LEFT"/>
      bcftools query -f &quot;%CHROM:%POS:%REF:%ALT\\t[%GT\\t]\\n&quot;<BR ALIGN="LEFT"/>
      Encode:<BR ALIGN="LEFT"/>
      • missing GT → NaN<BR ALIGN="LEFT"/>
      • any ALT allele present (contains '1') → 1<BR ALIGN="LEFT"/>
      • else → 0<BR ALIGN="LEFT"/>
      Save &lt;prefix&gt;.genomic_matrix.csv
    >];

    // Prebuilt matrix branch
    mat0 [label=<
      <B>CSV/TSV matrix mode</B><BR ALIGN="LEFT"/>
      Load sample × feature matrix as-is<BR ALIGN="LEFT"/>
      (Assumes already numeric/binary)
    >];

    // Metadata + known markers
    meta0 [label=<
      <B>load_metadata(meta_path)</B><BR ALIGN="LEFT"/>
      Read CSV/TSV<BR ALIGN="LEFT"/>
      Index = &quot;Sample&quot; column if present else first column<BR ALIGN="LEFT"/>
      Save metadata.normalized.csv
    > fillcolor="#e9fff2"];

    km0 [label=<
      <B>load_known_markers(known_markers_path)</B><BR ALIGN="LEFT"/>
      Accept .txt (one per line) OR .csv/.tsv<BR ALIGN="LEFT"/>
      Column &quot;marker&quot; or first column<BR ALIGN="LEFT"/>
      Save known_markers.normalized.txt
    > fillcolor="#e9fff2"];

    // Wire loader stage
    np_run -> dl_route;

    dl_route -> dl_dir [label="if directory"];
    dl_dir -> dl_choose;

    dl_choose -> union0 [label="UNION-of-sites"];
    union0 -> union1 -> union2 -> union_sem;

    dl_choose -> merge0 [label="MERGE-then-PARSE"];
    merge0 -> vcf0;

    dl_route -> vcf0 [label="if .vcf/.vcf.gz"];
    vcf0 -> vcf1 -> vcf2 -> vcf3 -> vcf4 -> vcf5 -> vcf6 -> vcf7;

    dl_route -> mat0 [label="if .csv/.tsv"];

    dl_route -> meta0 [style=dashed, label="if --meta"];
    dl_route -> km0   [style=dashed, label="if --known_markers"];
  }

  // ─────────────────────────────────────────────────────────────
  // STAGE 2 — DISCOVERY (pre-tree filtering + decision tree)
  // ─────────────────────────────────────────────────────────────
  subgraph cluster_discovery {
    label="Stage 2 — Feature discovery (decision_tree_builder.py)";
    labelloc="t";
    fontsize=14;
    style="rounded";
    color="#d7e3f7";

    disc_in [label=<
      <B>Inputs to discovery</B><BR ALIGN="LEFT"/>
      • genomic_matrix (samples × variants)<BR ALIGN="LEFT"/>
      • labels = metadata[label_column]<BR ALIGN="LEFT"/>
      • all_features = matrix columns
    >];

    pre0 [label=<
      <B>Pre-tree filtering (statistically defensible)</B><BR ALIGN="LEFT"/>
      1) Missingness gate: keep features with sufficient non-missing fraction<BR ALIGN="LEFT"/>
      2) MAF gate: keep features with MAF ≥ threshold<BR ALIGN="LEFT"/>
      3) Per-feature association test vs label:<BR ALIGN="LEFT"/>
         • Fisher for 2×2, else χ²<BR ALIGN="LEFT"/>
      4) Multiple testing correction: FDR-BH<BR ALIGN="LEFT"/>
      5) If none pass → fallback top-by-variance subset
    >];

    misslog [label=<
      <B>Missingness reporting</B><BR ALIGN="LEFT"/>
      Compute per-feature NaN fraction<BR ALIGN="LEFT"/>
      Log count of features above threshold<BR ALIGN="LEFT"/>
      (avoid printing thousands of names)
    > fillcolor="#fff2cc"];

    impute0 [label=<
      <B>Impute missing for tree fit</B><BR ALIGN="LEFT"/>
      NaN → 0 (treat missing as reference)<BR ALIGN="LEFT"/>
      Drop near-monomorphic after imputation
    >];

    tree0 [label=<
      <B>Train decision tree</B><BR ALIGN="LEFT"/>
      DecisionTreeClassifier(max_depth, min_samples_split, min_samples_leaf, random_state)<BR ALIGN="LEFT"/>
      Labels encoded with LabelEncoder
    >];

    rule0 [label=<
      <B>Interpretability outputs</B><BR ALIGN="LEFT"/>
      export_text(...) rules<BR ALIGN="LEFT"/>
      Root features = depth 0<BR ALIGN="LEFT"/>
      Branch features = depth &gt; 0
    >];

    conf0 [label=<
      <B>Confidence scoring (post-tree)</B><BR ALIGN="LEFT"/>
      For features used in tree:<BR ALIGN="LEFT"/>
      • Mutual information(feature, label)<BR ALIGN="LEFT"/>
      • Bootstrap stability of feature usage/importance<BR ALIGN="LEFT"/>
      • Effect size proxy: Cramér’s V<BR ALIGN="LEFT"/>
      Weighted aggregate → confidence score<BR ALIGN="LEFT"/>
      Save feature_confidence.json
    >];

    epi0 [label=<
      <B>Epistatic interaction mining (post-tree)</B><BR ALIGN="LEFT"/>
      Traverse root→leaf paths<BR ALIGN="LEFT"/>
      For adjacent feature pairs on a path:<BR ALIGN="LEFT"/>
      • compute MI-based synergy proxy<BR ALIGN="LEFT"/>
      • keep if ≥ epistasis_strength_threshold<BR ALIGN="LEFT"/>
      Cap number of interactions<BR ALIGN="LEFT"/>
      Save epistatic_interactions.json
    >];

    files0 [label=<
      <B>Files written</B><BR ALIGN="LEFT"/>
      • decision_tree_rules.txt<BR ALIGN="LEFT"/>
      • feature_confidence.json<BR ALIGN="LEFT"/>
      • epistatic_interactions.json
    > fillcolor="#e9fff2"];

    // connect discovery
    vcf7 -> disc_in [label="matrix"];
    union2 -> disc_in [label="matrix"];
    mat0 -> disc_in [label="matrix"];
    meta0 -> disc_in [style=dashed, label="labels from meta[label_column]"];

    disc_in -> pre0 -> misslog -> impute0 -> tree0 -> rule0 -> conf0 -> epi0 -> files0;
  }

  // ─────────────────────────────────────────────────────────────
  // STAGE 3 — VALIDATION (optional)
  // ─────────────────────────────────────────────────────────────
  subgraph cluster_validation {
    label="Stage 3 — Optional validation (statistical_validation.py)";
    labelloc="t";
    fontsize=14;
    style="rounded";
    color="#d7e3f7";

    v_in [label=<
      <B>Validation inputs</B><BR ALIGN="LEFT"/>
      • matrix (samples × variants)<BR ALIGN="LEFT"/>
      • labels<BR ALIGN="LEFT"/>
      • discovered features / interactions (from Stage 2)
    >];

    v_assoc [label=<
      <B>Feature association tests</B><BR ALIGN="LEFT"/>
      chi_squared_test(): χ²/Fisher + MI + Cramér’s V<BR ALIGN="LEFT"/>
      Save chi_squared_results.json
    >];

    v_mtest [label=<
      <B>Multiple testing correction</B><BR ALIGN="LEFT"/>
      multiple_testing_correction(): FDR-BH / Bonferroni<BR ALIGN="LEFT"/>
      Save multiple_testing_results.json
    >];

    v_boot [label=<
      <B>Bootstrap validation</B><BR ALIGN="LEFT"/>
      bootstrap_validation(): stability &amp; importance distributions<BR ALIGN="LEFT"/>
      Save bootstrap_results.json
    >];

    v_perm [label=<
      <B>Interaction permutation tests</B><BR ALIGN="LEFT"/>
      permutation_test_interactions(): permutation p-values for candidate pairs<BR ALIGN="LEFT"/>
      Save interaction_permutation_results.json
    >];

    v_note [label=<
      <B>Implementation note</B><BR ALIGN="LEFT"/>
      Orchestrator calls validate_features()/validate_interactions()<BR ALIGN="LEFT"/>
      but StatisticalValidator exposes chi_squared_test(), multiple_testing_correction(),<BR ALIGN="LEFT"/>
      bootstrap_validation(), permutation_test_interactions().<BR ALIGN="LEFT"/>
      Wrapper methods or call-site update required for flags to work.
    > fillcolor="#ffe6e6"];

    // connect validation
    files0 -> v_in [style=dashed, label="if flags enabled"];
    v_in -> v_assoc -> v_mtest -> v_boot;
    v_in -> v_perm;
    v_note -> v_in [style=dotted];
  }

  // ─────────────────────────────────────────────────────────────
  // STAGE 4 — FINAL REPORT
  // ─────────────────────────────────────────────────────────────
  subgraph cluster_report {
    label="Stage 4 — Final synthesis (network_parser.py + utils.py)";
    labelloc="t";
    fontsize=14;
    style="rounded";
    color="#c9d7f0";

    out0 [label=<
      <B>Assemble results dictionary</B><BR ALIGN="LEFT"/>
      • timestamp()<BR ALIGN="LEFT"/>
      • config snapshot vars(config)<BR ALIGN="LEFT"/>
      • discovery outputs (features, rules, confidence, interactions)<BR ALIGN="LEFT"/>
      • validation outputs (if executed)
    >];

    out1 [label=<
      <B>Write final JSON</B><BR ALIGN="LEFT"/>
      save_json(networkparser_results_&lt;timestamp&gt;.json)<BR ALIGN="LEFT"/>
      ensure_dir(output_dir)
    > fillcolor="#e9fff2"];
  }

  // wire final stage
  np_run -> out0;
  files0 -> out0;
  v_boot -> out0 [style=dashed];
  v_perm -> out0 [style=dashed];
  out0 -> out1;

  // ─────────────────────────────────────────────────────────────
  // Dependency callouts (what it uses)
  // ─────────────────────────────────────────────────────────────
  subgraph cluster_deps {
    label="What it uses (tools + libraries)";
    labelloc="t";
    fontsize=14;
    style="rounded";
    color="#e2e2e2";

    dep_tools [label=<
      <B>External tools</B><BR ALIGN="LEFT"/>
      • bcftools: norm, view, filter, merge, query<BR ALIGN="LEFT"/>
      • tabix: index .vcf.gz
    > fillcolor="#f4f4f4"];

    dep_py [label=<
      <B>Python</B><BR ALIGN="LEFT"/>
      • pandas, numpy<BR ALIGN="LEFT"/>
      • scipy.sparse (optional, for union mode scale)<BR ALIGN="LEFT"/>
      • scikit-learn (DecisionTreeClassifier, LabelEncoder, MI)<BR ALIGN="LEFT"/>
      • scipy.stats, statsmodels (FDR-BH etc.)<BR ALIGN="LEFT"/>
      • joblib (parallel validation)<BR ALIGN="LEFT"/>
      • concurrent.futures (threaded indexing)
    > fillcolor="#f4f4f4"];
  }

  // connect deps lightly
  vcf0 -> dep_tools [style=dotted];
  union1 -> dep_tools [style=dotted];
  pre0 -> dep_py [style=dotted];
  v_assoc -> dep_py [style=dotted];
}
